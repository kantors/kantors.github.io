<!DOCTYPE html>
<html>

<head>
    <link rel="stylesheet" href="../main.css">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
    <link href="https://fonts.googleapis.com/css?family=Fira+Sans+Extra+Condensed:400,500,600,700|Fira+Sans:300,400,500" rel="stylesheet">
    <script src="../main.js"></script>
    <script src="../js/portfolio.js"></script>
</head>

<body>
    <div class="writting-piece portfolio-page content-wrapper">
        <div class="navigation">
            <ul>
                <li>
                    <a href="../index.html"><img src="../assets/logo.svg"></a>
                    </img>
                </li>
                <li class="link"><a href="../index.html#work-section">Work</a></li>
                <li class="link"><a href="../assets/resume.pdf">Resume</a></li>
            </ul>
        </div>
        <div class="portfolio-header">
            <div class="hidden-header">
                <div class="text-wrapper">
                    <p class="type">Writing</p>
                    <h1>Ethical Issues in the Cyber Security Sphere for At-Risk Citizens</h1>
                </div>

            </div>
        </div>
        <div class="section info-section text-section hideme">
            <div class="info-wrapper">
                <div class="sub-section">
                    <h2>Type Of Work</h2>
                    <p>Writing</p>
                </div>
                <div class="sub-section">
                    <h2>Context</h2>
                    <p></p>
                </div>
                <div class="sub-section">
                    <h2>Year</h2>
                    <p>2017</p>
                </div>
            </div>
        </div>
        <div class="content article">
            <p>Dear Dr. Maughan, Mr. Tousley, Dr. Carlsten, and Mr. Garwood,</p>
            <p>We are pleased to submit to you this report on the ethical implications of data mining related to United States citizens. This report discusses the developing issues and growing ethical challenges of data mining, specifically those targeting
                at-risk United States citizens. Using perspectives gathered from multiple industries and authors, we describe potential advantages of data mining but also the multiple ethical breaches that are occurring across various industries in the
                cyber sphere.
            </p>
            <p>In addition, our report focuses on the growing issue of “weblining”, and how companies utilize it for the practice of price discrimination, predictive marketing, and other targeting techniques for at risk consumers. These issues reflect a
                need for greater regulation from the Department of Homeland Security in an effort to ensure all United States citizens are able to have a safe, fair, and equitable online experience. We look forward to presenting to you our findings.
            </p>
            <p>
                Sincerely, </br>
                Kate Holmes </br> Bachelor of Science in Economics and Business Administration</br> Northeastern University
            </p>
            <p>
                Sabrina Kantor </br> Bachelor of Science in Computer Science and Interactive Media </br>Northeastern University
            </p>
            <h2>Context Note</h2>
            <p>
                Most people with a savvy online presence are aware that companies use their online profiles to the firm’s advantage. However, even knowledgeable consumers are probably unaware to what extent this occurs. It goes beyond a company changing airline fares
                depending on demand. Companies using data mining techniques regularly cross ethical lines. We are focusing this issue to the government, as we believe these ethical breaches would not be occurring if the government were already aware of
                the issue and would be taking action to change it.
            </p>
            <h2>Topic Overview</h2>
            <p>
                Data mining and the use of big data have been steadily growing across many different fields. As technology advances, data mining becomes an increasingly powerful tool to gain insights into consumers and also to target specific viewers. However, the ethics
                of data mining is still a largely unexplored topic. As a result, the laws and regulations surrounding data protection are insufficient to protect the general population from the harm that arises from the current data mining practices used
                by certain companies, particularly as those practices unfairly target at-risk citizens. For example, many citizens are unaware of what data is being collected from them and for what purpose. Not only is this a serious privacy concern,
                but it also allows corporations to benefit from their users without their knowledge in potentially unethical ways.
            </p>
            <p>
                Companies and organizations treat users differently based on their private data, whether it be charging a higher insurance premium due to a user’s search history or giving a certain demographic group better deals because they are more likely to drive
                profits. Few people read the fine print that describes what their private data is being used for, and fewer are aware of the discrimination or privacy invasion that they may be facing because of it.
            </p>
            <p>
                If we define an ethical society as one where, “all citizens’ equal basic rights and liberties and fair opportunities are secure” (Rawls, pg. 59), it is easy to recognize that the online sphere is not “ethical”. Currently, those with low computer literacy
                rates are being targeted by companies through the act of weblining, which leads to price discrimination, invasive marketing techniques, and other targeting techniques that companies use to take advantage of at-risk citizens.
            </p>
            <h2>Weblining</h2>
            <p>
                Through the use of data collected online, companies can sort and segment by certain user characteristics, e.g. income bracket, race, age, and geographic location. By identifying these characteristics and patterns in users, companies are able to offer
                certain products and services at certain prices purely based on users’ segmented characteristics in order to boost profits. This creates the possibility of weblining, where consumers with less desirable online profiles are denied certain
                goods or prices from companies. Some more savvy consumers may be aware of this. For example, those experienced in airline ticket purchasing recognize what the airline industry is doing to get them on their flights. However, most consumers,
                especially those with a low computer literacy rate, and even the government, are unaware just how pervasive these discriminatory practices are. Examples of weblining and the ethical issues it raises are outlined below.
            </p>
            <h2>Targeting at-risk groups and using price discrimination</h2>
            <p>
                The act of weblining is becoming a pervasive issue in the insurance industry. Starting in the 1900s, it was documented that insurers openly discriminated against certain races through insurance policies. This practice, also known as insurance redlining,
                consisted of policy cancellations and a refusal to renew insurance policies based on the location of neighborhoods that were predominantly black. By denying these neighborhoods insurance, the companies created systematic barriers based
                on race.
            </p>
            <p>
                The same behavior is now occurring online. In a paper published by Gary Hernandez and Katherine Eddy, the authors define weblining as the practice of denying someone access and service based on their online presence, or denying them because they don’t
                have an online presence. There is a large gap between communities who are considered computer literate and are able to adopt and effectively use information technology and those that are not. According to a study done at UCLA, educated
                white male users were more likely to have computer literacy compared to African-Americans, Latinos and female users who were least likely to have knowledge of it (Hernandez et al).
            </p>
            <p>
                These less computer literate groups of people can be easily identified through their computer data which insurance companies can buy or track. Insurance companies will segment these groups as “high risk” and will not offer them insurance policies by simply
                putting the policies online (which they are less likely to access) or by offering them to these groups at a higher price overall. One example of this came from Reliance Direct, which offered customers a $50 discount if they lived in certain
                specified neighborhoods. Another example in a different industry is Kozmo.com. This online delivery service came under fire for price discrimination and weblining in Washington D.C. While D.C has a 66% black population, Kozmo only served
                predominantly white areas (the racial makeup of its communities served were made up of 65% white residents). To put this is into numbers, Kozmo did not serve 350,000 of the 400,000 black residents, while 130,000 out of 170,000 of D.C’s
                white residents were served (Zaret et al). Kozmo essentially excluded specific neighborhoods and communities because of characteristics based on the personal online profile of their customer base. While this case was never taken to trial,
                the Equal Rights Center (ERC) initiated a claim, stating that Kozmo’s pattern of business clearly resembled how banks used redlining before laws prohibited it.
            </p>
            <p>
                Identifying factors like race and income level, and by subsequently limiting an individual’s online options based on where they live should be considered unlawful discrimination. Not doing so violates Rawl’s definition of an ethical society, where equal
                opportunities are given to all members of society.
            </p>
            <h2>Weblining using targeted advertisements</h2>
            <p>
                Another form of Weblining occurs when companies place potential customers into groups or profiles in order to target them through advertisements. This is a successful strategy that allows companies to reap many benefits at the expense of their customers.
                For examples, a teenage girl will be sent targeted advertisements based on her age and gender. This perpetuates stereotypes, and in some cases, leads to discrimination. In a study conducted at Carnegie Mellon, an advertisement for a career
                coaching service for executive jobs was shown to over 1,852 males compared to just 318 women (Datta et al). Other studies have discovered online ads suggest arrest records occur more frequently when searching names that are more often
                given to black children. Discrimination and racial profiling like this is hard to detect, as Internet users are only aware of the ads that they view. Furthermore, these advertisements are being shown based on decisions made by algorithms
                not people. By giving all decision power to algorithms, corporations fail to use their data responsibly resulting in discriminatory and unfair advertisements.
            </p>
            <h2>Targeting at-risk groups’ privacy</h2>
            <p>
                Weblining also targets at risk groups that can be identified through tracked consumer data. In their report Danna and Gandy write, “...more information is being captured in Web server logs. Sophisticated analytics and data mining software tools enable
                firms to use the data contained in these logs to develop and implement a complex relationship management strategy” (pg. 373). Those with higher consumer literacy rates are more aware of this storage and mining process taking place, and
                are therefore more likely to take steps to prevent it to protect their privacy. Still, the majority of adults do not fully understand the privacy and disclosure policy companies put forth and are unknowingly signing away their right to
                data privacy. Certain groups that are identified through weblining are specifically targeted by companies who are aware they will divulge personal information and data more easily than others.
            </p>
            <p>One example of a highly targeted group is kids. Children have a low computer literacy rate and are very likely to be victims of data mining. With an incentive of a reward or prize, kids are much more likely than adults to hand out personal
                information to companies. This begs the question: Are these companies gaining full consent from their customer base or is this unethical behavior by firms who are taking advantage of unsuspecting customers.</p>
            <p>Companies serving children, encourage data mining through games, incentives, and membership rewards. Not only do companies collect personal information, which children are more likely to give up, they are also collecting data on the user’s
                browsing habits and online preferences, which can be sold to other companies as market data. In the example of Postopia.com, kids are encouraged to earn points by submitting a code found on their cereal boxes. Kids, who have most likely
                unknowingly signed away their privacy rights, are now providing the company with a continuous supply of market data and personal information.</p>
            <p>The ethical issues here are more than just privacy concerns for the kids. It is the fact that companies are going after groups who are tagged as being computer illiterate and taking advantage of them to increase their profits. This would not
                be considered a society where “all citizens’ equal basic rights and liberties and fair opportunities are secure”. Certain citizens are being offered an unsafe cyberspace and are not being protected as much as they should be.</p>
            <h2>Advantages of data mining</h2>
            <p>Companies that are able to collect large amounts of data from their customers are able to turn that data into powerful insights about their customers. Using data to create targeted advertisements is a more successful and efficient marketing
                strategy. Companies aren’t the only ones that benefit from data mining; consumers also benefit. Many prefer seeing relevant ads as well as recommendations based on previous purchases. This allows consumers to more efficiently find what
                they are looking for. Furthermore, the use of data mining in fields such as genomics and healthcare have the potential to positively impact the field in far reaching ways. With the ability to collect increasing amounts of data on individuals,
                companies that are able to analyze this data will gain powerful insights. However, this data represents some of the most sensitive and private information about a person and can be used to both benefit and harm the individual in powerful
                ways.
            </p>
            <h2>Potential Solutions</h2>
            <p>Because of the many benefits of data mining, it is essential that lawmakers develop a way to regulate data collection to protect online an online user’s privacy and rights. Laws need to be put into place that requires companies to be more
                transparent with their customers. Terms of services must be more transparent and be written in layman’s terms. In addition, it should be made clear to the user exactly what data is being collected and for what reason. There are already
                companies that do a good job of this. For example, Kickstarter, a global crowd funding platform, clearly describes their terms of service in a way that the average user can understand. While they are required to state their terms of service
                using legal language, they also provide a simple summary and explanation for each term. This kind of transparency is rarely seen from companies but should become the industry standard. In addition, they make clear to their users what data
                they are collecting and how they will use this data. This is a perfect example of the steps a company can take in order to maintain an ethical relationship with their users. Another regulation to consider is the prohibition on the collection
                and use of certain kinds of sensitive data. Companies should not be allowed to use data relating to race and income level to either webline by either modifying prices of consumer goods or by modifying access to services. This is a form
                of discrimination and should be treated as such.</p>
            <h2>Conclusion</h2>
            <p>As data collection becomes increasingly commonplace, it is essential that laws and regulations evolve to protect Internet users. Not only is the number of Internet users increasing, but there is also an increase in the sensitivity of the data
                being collected. The growing Internet of Things allows corporations to track even more of a user’s intimate data relating to areas such as health and location. If restrictive laws are not put in place, corporations will be able use this
                data in ways that take advantage of online users. As technology advances, data mining only becomes more powerful, and as a result, the laws governing it and it’s practices become even more important.
            </p>
            <h2>Citations</h2>
            <p>Danna, Anthony & Gandy Jr, Oscar H. (2002). All that glitters is not gold: Digging beneath the surface of data mining. Journal of Business Ethics, 40 373-386.</p>
            <p>Datta, A., Tschantz, M. & Datta, A. (2015). Automated Experiments on Ad Privacy Settings. Proceedings on Privacy Enhancing Technologies, 2015(1), pp. 92-112. Retrieved 6 Nov. 2017, from doi:10.1515/popets-2015-0007</p>
            <p>Eliot Zaret and Brock N. Meeks, Kozmo’s Digital Dividing Lines, MSNBC.com (April. 11 2000), at http://www.msnbc.com/news/394407.asp</p>
            <p>Rawls, J. (1971). A Theory of Justice. Cambridge, MA: Belknap Press Hernandez, Gary A.; Eddy, Katherine J.; Muchmore, Joel. "Insurance Weblining and Unfair Discrimination in Cyberspace." SMU Law Review54.4 (2001): 1953-1972.</p>
        </div>
    </div>
</body>

</html>
